{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_6codqFnXgi"
      },
      "source": [
        "# SVM for classification, without and with kernels\n",
        "\n",
        "In this notebook we are going to explore the use of Support Vector Machines (SVMs) for image classification. We are going to use the famous MNIST dataset, that is a dataset of handwritten digits. We get the data from mldata.org, that is a public repository for machine learning data.\n",
        "\n",
        "The dataset consists of 70,000 images of handwritten digits (i.e., 0, 1, ... 9). Each image is 28 pixels by 28 pixels and we can think of it as a vector of 28x28 = 784 numbers. Each number is an integer between 0 and 255. For each image we have the corresponding label (i.e., 0, 1, ..., 9)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "w7owrXabnXgn"
      },
      "outputs": [],
      "source": [
        "# Load the required packages\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import sklearn\n",
        "from sklearn.datasets import fetch_openml"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f1Q2n9z_nXgr"
      },
      "source": [
        "Now let's load the dataset. 'data' contains the input, 'target' contains the label. We normalize the data by dividing each value by 255 so that each value is in [0,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Zn7ErChanXgs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6be143e-2b2d-4fdc-ad80-b4535d71e8a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# TODO: Normalize MNIST dataset and rescale the data\n",
        "\n",
        "# Loading the MNIST dataset and normalize the features so that each value is in the range [0,1]\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "\n",
        "# Rescaling the data\n",
        "X, y = mnist.data.to_numpy() / 255., mnist.target.to_numpy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "THXcR9T1nXgu"
      },
      "source": [
        "Now split into training and test. We keep 500 samples in the training set. Make sure that each label is present at least 10 times\n",
        "in training. If it is not, then keep adding permutations to the initial data until this\n",
        "happens.\n",
        "\n",
        "**IMPORTANT**: if you cannot run the SVM with 500 samples or 1000 samples (see below), try with a smaller number of samples (e.g. 200 here and 400 below)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "mK2rPXy3nXgv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a704915-b910-42e8-af75-955f3555e2a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels and their frequencies in the training dataset: \n",
            "0: 49\n",
            "1: 60\n",
            "2: 35\n",
            "3: 56\n",
            "4: 51\n",
            "5: 47\n",
            "6: 46\n",
            "7: 63\n",
            "8: 48\n",
            "9: 45\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Randomly permute the data and split it into training and test sets, taking the first 500\n",
        "# data samples as training and the rest as test.\n",
        "\n",
        "permutation = np.random.permutation(X.shape[0])\n",
        "\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "\n",
        "m_training = 500\n",
        "\n",
        "X_train, X_test = X[:m_training], X[m_training:]\n",
        "y_train, y_test = y[:m_training], y[m_training:]\n",
        "\n",
        "# Printing the labels and their frequencies in the training dataset\n",
        "\n",
        "print(\"Labels and their frequencies in the training dataset: \")\n",
        "unique_labels, label_counts = np.unique(y_train, return_counts=True)\n",
        "for label, count in zip(unique_labels, label_counts):\n",
        "    print(f\"{label}: {count}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using \".permutation\" we actually shuffle the data."
      ],
      "metadata": {
        "id": "Wd-tqvg4_4Ko"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45ksUODunXgw"
      },
      "source": [
        "We now provide a function to print an image in a dataset, the corresponding true label, and the index of the image in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def plot_digit(X_matrix, labels, index):\n",
        "  \"\"\"\n",
        "  Plots a digit from the X_matrix and prints the corresponding label.\n",
        "  Args:\n",
        "  X_matrix (numpy.ndarray): Matrix of digit images.\n",
        "  labels (numpy.ndarray): Array of digit labels.\n",
        "  index (int): Index of the digit to plot and print.\n",
        "  \"\"\"\n",
        "  print(\"INPUT:\")\n",
        "  plt.imshow(\n",
        "      X_matrix[index].reshape(28,28),\n",
        "      cmap          = plt.cm.gray_r,\n",
        "      interpolation = \"nearest\"\n",
        "  )\n",
        "  plt.show()\n",
        "  print(\"LABEL: %s\" % labels[index])\n"
      ],
      "metadata": {
        "id": "TeXh2BpHrd-5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\"interpolation='nearest'\" simply displays an image without trying to interpolate between pixels if the display resolution is not the same as the image resolution (which is most often the case). It will result an image in which pixels are displayed as a square of multiple pixels."
      ],
      "metadata": {
        "id": "XgNPBLURA_LJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEDj_SMOnXgz"
      },
      "source": [
        "As an example, let's print the 100-th image in X_train and the 40,000-th image in X_test and their true labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "9USuS-ztnXg1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 912
        },
        "outputId": "26f14a47-3fc8-496a-eda9-494bbca73655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 1\n",
            "INPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 2\n"
          ]
        }
      ],
      "source": [
        "# Plotting the 100th digit in the training set\n",
        "plot_digit(X_train, y_train, 100)\n",
        "\n",
        "# Plotting the 40,000th digit in the test set\n",
        "plot_digit(X_test, y_test,40000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dp9-uKtFnXg4"
      },
      "source": [
        "## Section 1\n",
        "Run SVM with cross validation to pick a kernel and values of parameters. Use a 5-fold cross-validation to pick the best kernel and choice of parameters. We provide some potential choice for parameters, but change the grid if needed (e.g., it takes too long). For the SVM for classification use SVC from sklearn.svm; for the grid search we suggest you use GridSearchCV from sklearn.model_selection, but you can implement your own cross-validation for model selection if you prefer.\n",
        "\n",
        "Print the best parameters used as well as the score obtained by the best model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Importing the Support Vector Classifier (SVC) and GridSearchCV modules\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "# Setting the parameters for the linear SVM\n",
        "parameters = {'C': [1, 10, 100]}\n",
        "\n",
        "# Creating a linear SVM object\n",
        "linear_SVM = SVC(kernel='linear')\n",
        "\n",
        "# TO DO: Find the best model using 5-fold cross-validation and train it using all the training data\n",
        "\n",
        "cv = 5\n",
        "grid_search = GridSearchCV(estimator=linear_SVM, param_grid=parameters, cv=cv)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Printing the results for the linear kernel\n",
        "print('RESULTS FOR LINEAR KERNEL\\n')\n",
        "\n",
        "# Printing the best parameters set\n",
        "print(\"Best parameters set found:\")\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "\n",
        "# Printing the score of the best parameters set\n",
        "print(\"Score with best parameters:\")\n",
        "\n",
        "best_score = grid_search.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Printing all the scores of the different parameters set\n",
        "print(\"\\nAll scores on the grid:\")\n",
        "\n",
        "cv_results = grid_search.cv_results_\n",
        "\n",
        "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Parameters:\", params)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "# Setting the parameters for the polynomial kernel with degree 2\n",
        "parameters = {'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1.]}\n",
        "\n",
        "# Creating a polynomial kernel with degree 2 SVM object\n",
        "poly2_SVM = SVC(kernel='poly', degree=2)\n",
        "\n",
        "# TO DO: Find the best model using 5-fold cross-validation and train it using all the training data\n",
        "\n",
        "grid_search = GridSearchCV(estimator=poly2_SVM, param_grid=parameters, cv=cv)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Printing the results for the polynomial kernel with degree 2\n",
        "print('\\nRESULTS FOR POLY DEGREE=2 KERNEL\\n')\n",
        "\n",
        "# Printing the best parameters set\n",
        "print(\"Best parameters set found:\")\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "\n",
        "# Printing the score of the best parameters set\n",
        "print(\"Score with best parameters:\")\n",
        "\n",
        "best_score = grid_search.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Printing all the scores of the different parameters set\n",
        "print(\"\\nAll scores on the grid:\")\n",
        "\n",
        "cv_results = grid_search.cv_results_\n",
        "\n",
        "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Parameters:\", params)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "# Setting the parameters for the RBF kernel\n",
        "parameters = {'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1.]}\n",
        "\n",
        "# Creating an RBF kernel SVM object\n",
        "rbf_SVM = SVC(kernel='rbf')\n",
        "\n",
        "# TO DO: Find the best model using 5-fold cross-validation and train it using all the training data\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rbf_SVM, param_grid=parameters, cv=cv)\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Printing the results for the RBF kernel\n",
        "print('\\nRESULTS FOR RBF KERNEL\\n')\n",
        "\n",
        "# Printing the best parameters set\n",
        "print(\"Best parameters set found:\")\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "\n",
        "# Printing the score of the best parameters set\n",
        "print(\"Score with best parameters:\")\n",
        "\n",
        "best_score = grid_search.best_score_\n",
        "print(best_score)\n",
        "\n",
        "# Printing all the scores of the different parameters set\n",
        "print(\"\\nAll scores on the grid:\")\n",
        "\n",
        "cv_results = grid_search.cv_results_\n",
        "\n",
        "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Parameters:\", params)\n",
        "    print(\"\")\n"
      ],
      "metadata": {
        "id": "49FHb1CKuSa2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7619d9b-6b68-40ab-a6aa-0e85eefcdbf4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RESULTS FOR LINEAR KERNEL\n",
            "\n",
            "Best parameters set found:\n",
            "{'C': 1}\n",
            "Score with best parameters:\n",
            "0.882\n",
            "\n",
            "All scores on the grid:\n",
            "Mean Score: 0.882\n",
            "Parameters: {'C': 1}\n",
            "\n",
            "Mean Score: 0.882\n",
            "Parameters: {'C': 10}\n",
            "\n",
            "Mean Score: 0.882\n",
            "Parameters: {'C': 100}\n",
            "\n",
            "\n",
            "RESULTS FOR POLY DEGREE=2 KERNEL\n",
            "\n",
            "Best parameters set found:\n",
            "{'C': 10, 'gamma': 0.01}\n",
            "Score with best parameters:\n",
            "0.892\n",
            "\n",
            "All scores on the grid:\n",
            "Mean Score: 0.852\n",
            "Parameters: {'C': 1, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 1, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 1, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.892\n",
            "Parameters: {'C': 10, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 10, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 10, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 100, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 100, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.89\n",
            "Parameters: {'C': 100, 'gamma': 1.0}\n",
            "\n",
            "\n",
            "RESULTS FOR RBF KERNEL\n",
            "\n",
            "Best parameters set found:\n",
            "{'C': 10, 'gamma': 0.01}\n",
            "Score with best parameters:\n",
            "0.9\n",
            "\n",
            "All scores on the grid:\n",
            "Mean Score: 0.8940000000000001\n",
            "Parameters: {'C': 1, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.458\n",
            "Parameters: {'C': 1, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.134\n",
            "Parameters: {'C': 1, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.9\n",
            "Parameters: {'C': 10, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.49399999999999994\n",
            "Parameters: {'C': 10, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.14200000000000002\n",
            "Parameters: {'C': 10, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.9\n",
            "Parameters: {'C': 100, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.49399999999999994\n",
            "Parameters: {'C': 100, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.14200000000000002\n",
            "Parameters: {'C': 100, 'gamma': 1.0}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sECvVFNvnXg6"
      },
      "source": [
        "## Section 2\n",
        "For the \"best\" SVM kernel and choice of parameters from above, train the model on the entire training set and measure the training error. Also make predictions on the test set and measure the test error. Print the training and the test error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sk0mqc0QnXg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad669745-663f-4660-d382-cc279232861c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM training error: 0.000000\n",
            "Best SVM test error: 0.108604\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Getting the best SVM model from cross-validation\n",
        "best_SVM = SVC(kernel='rbf', C=10, gamma=0.01)\n",
        "\n",
        "# Fitting the model on the entire training set\n",
        "best_SVM.fit(X_train, y_train)\n",
        "\n",
        "# Getting the training and test error\n",
        "training_error = 1. - best_SVM.score(X_train, y_train)\n",
        "test_error = 1. - best_SVM.score(X_test, y_test)\n",
        "\n",
        "# Printing the training and test error for the best SVM model\n",
        "print(\"Best SVM training error: %f\" % training_error)\n",
        "print(\"Best SVM test error: %f\" % test_error)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nMoD65fnXg6"
      },
      "source": [
        "## Use logistic regression for comparison\n",
        "\n",
        "## Section 3\n",
        "\n",
        "Just for comparison let's also use logistic regression, first with the default values of the parameter for regularization and then with cross-validation to fix the value of the parameter. For cross validation, use 5-fold cross validation and the default values of the regularization parameters for the function linear_model.LogisticRegressionCV(...)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn import linear_model\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "# Creating a logistic regression object\n",
        "lr = linear_model.LogisticRegression()\n",
        "\n",
        "# TODO: Fit the model on the training data\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "# Computing the training and test error for the logistic regression model\n",
        "training_error = 1. - lr.score(X_train, y_train)\n",
        "test_error = 1. - lr.score(X_test, y_test)\n",
        "\n",
        "print(\"Best logistic regression training error: %f\" % training_error)\n",
        "print(\"Best logistic regression test error: %f\" % test_error)\n",
        "\n",
        "\n",
        "# Use logistic regression with 5-fold cross-validation\n",
        "# You can use linear_model.LogisticRegressionCV\n",
        "# Use 5-fold cross-validation to find the best choice of the parameter, then train\n",
        "# the model on the entire training set\n",
        "\n",
        "lr_cv = linear_model.LogisticRegressionCV(cv=cv, random_state=0)\n",
        "\n",
        "# Finding the best parameter's score and then take the average to compute the error\n",
        "training_error_cv = 1. - sklearn.model_selection.cross_val_score(lr_cv, X_train, y_train, cv=cv).mean()\n",
        "\n",
        "lr_cv.fit(X_train, y_train)\n",
        "\n",
        "test_error_cv = 1. - lr_cv.score(X_test, y_test)\n",
        "\n",
        "print(\"Best logistic regression training error: %f\" % training_error_cv)\n",
        "print(\"Best logistic regression test error: %f\" % test_error_cv)\n"
      ],
      "metadata": {
        "id": "lHBdJ76QtwDB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "814d4dc9-f773-4b84-e5a0-7f431240abea"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best logistic regression training error: 0.000000\n",
            "Best logistic regression test error: 0.151223\n",
            "Best logistic regression training error: 0.140000\n",
            "Best logistic regression test error: 0.150791\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First of all we import \"warnings\" library and ignore them to prevent the long and disturbing texts generated.\n",
        "\n"
      ],
      "metadata": {
        "id": "J1C-u12T0jOk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D1zBeUFYnXg8"
      },
      "source": [
        "## Section 4\n",
        "Compare and comment the results from SVM and logistic regression."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the results from the Section 2 and Section 3.2, which are showing the best outputs of the $2$ methods, we conclude that the SVM method performs better on the MNIST dataset.\n",
        "\n",
        "- The SVM is known for its ability to handle non-linear decision boundaries effectively through the use of kernel functions. The MNIST dataset consists of handwritten digits, which may have complex and non-linear patterns. The SVM's ability to capture such patterns might have contributed to its superior performance compared to logistic regression, which assumes linear decision boundaries by default.\n",
        "\n",
        "- SVMs can implicitly perform feature transformations using kernel functions. This transformation can map the original feature space into a higher-dimensional space, making it easier to separate the classes. In the case of the MNIST dataset, the SVM might have benefited from this implicit feature transformation to better discriminate between the different digit classes.\n",
        "\n",
        "- SVMs are generally more robust to outliers due to their margin maximization objective. Outliers, if present in the MNIST dataset, might have less impact on the SVM's decision boundary compared to logistic regression, which minimizes the least squares loss.\n",
        "\n",
        "- SVMs can capture complex relationships in the data by utilizing different kernel functions. This flexibility allows the SVM to fit the training data more closely, potentially resulting in better generalization and improved performance on the test set. Logistic regression, being a linear model, might have limitations in capturing highly complex relationships in the MNIST dataset.\n",
        "\n",
        "It's important to note that the performance comparison may vary based on the specific dataset and the tuning of the models."
      ],
      "metadata": {
        "id": "bBqlVV4B2nsw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjEGnvoynXg8"
      },
      "source": [
        "## Section 5\n",
        "Write the code that finds and plots a digit that is missclassified by logistic regression (optimized for the regularization parameter) and correctly classified by the \"best\" SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "md8_fNFxnXg8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "0eb73e2e-052a-433c-8054-570d36b3a419"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 3\n",
            "Logistic regression Label: 5\n",
            "SVM Label: 3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Predicting the test set by bith methods\n",
        "\n",
        "y_pred_SVM = best_SVM.predict(X_test)\n",
        "y_pred_lr = lr_cv.predict(X_test)\n",
        "\n",
        "# Iterating over the test set and finding the label not equal with the first method's prediction, then repeating for the second method\n",
        "for i in range(len(X_test)):\n",
        "  if y_test[i] != y_pred_lr[i]:\n",
        "    if y_test[i] == y_pred_SVM[i]:\n",
        "      plot_digit(X_test, y_test, i)\n",
        "      print(\"Logistic regression Label: %s\" % y_pred_lr[i])\n",
        "      print(\"SVM Label: %s\" % y_pred_SVM[i])\n",
        "      break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrWB8rZvnXg9"
      },
      "source": [
        "## More data\n",
        "Now let's do the same but using 1000 data points for training.\n",
        "\n",
        "## Section 6\n",
        "Repeat the entire analysis above using 1000 samples. Of course you can copy the code from above."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "permutation = np.random.permutation(X.shape[0])\n",
        "\n",
        "X = X[permutation]\n",
        "y = y[permutation]\n",
        "\n",
        "m_training = 1000\n",
        "\n",
        "X_train, X_test = X[:m_training], X[m_training:]\n",
        "y_train, y_test = y[:m_training], y[m_training:]\n",
        "\n",
        "print(\"Labels and their frequencies in the training dataset: \")\n",
        "unique_labels, label_counts = np.unique(y_train, return_counts=True)\n",
        "for label, count in zip(unique_labels, label_counts):\n",
        "    print(f\"{label}: {count}\")\n",
        "\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "parameters = {'C': [1, 10, 100]}\n",
        "\n",
        "linear_SVM = SVC(kernel='linear')\n",
        "\n",
        "cv = 5\n",
        "grid_search = GridSearchCV(estimator=linear_SVM, param_grid=parameters, cv=cv)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('RESULTS FOR LINEAR KERNEL\\n')\n",
        "print(\"Best parameters set found:\")\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "print(\"Score with best parameters:\")\n",
        "best_score = grid_search.best_score_\n",
        "print(best_score)\n",
        "print(\"\\nAll scores on the grid:\")\n",
        "cv_results = grid_search.cv_results_\n",
        "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Parameters:\", params)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "parameters = {'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1.]}\n",
        "\n",
        "poly2_SVM = SVC(kernel='poly', degree=2)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=poly2_SVM, param_grid=parameters, cv=cv)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('\\nRESULTS FOR POLY DEGREE=2 KERNEL\\n')\n",
        "print(\"Best parameters set found:\")\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "print(\"Score with best parameters:\")\n",
        "best_score = grid_search.best_score_\n",
        "print(best_score)\n",
        "print(\"\\nAll scores on the grid:\")\n",
        "cv_results = grid_search.cv_results_\n",
        "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Parameters:\", params)\n",
        "    print(\"\")\n",
        "\n",
        "\n",
        "parameters = {'C': [1, 10, 100], 'gamma': [0.01, 0.1, 1.]}\n",
        "\n",
        "rbf_SVM = SVC(kernel='rbf')\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rbf_SVM, param_grid=parameters, cv=cv)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "print('\\nRESULTS FOR RBF KERNEL\\n')\n",
        "print(\"Best parameters set found:\")\n",
        "best_params = grid_search.best_params_\n",
        "print(best_params)\n",
        "print(\"Score with best parameters:\")\n",
        "best_score = grid_search.best_score_\n",
        "print(best_score)\n",
        "print(\"\\nAll scores on the grid:\")\n",
        "cv_results = grid_search.cv_results_\n",
        "for mean_score, params in zip(cv_results['mean_test_score'], cv_results['params']):\n",
        "    print(\"Mean Score:\", mean_score)\n",
        "    print(\"Parameters:\", params)\n",
        "    print(\"\")\n",
        "\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "best_SVM = SVC(kernel='rbf', C=10, gamma=0.01)\n",
        "best_SVM.fit(X_train, y_train)\n",
        "\n",
        "training_error = 1. - best_SVM.score(X_train, y_train)\n",
        "test_error = 1. - best_SVM.score(X_test, y_test)\n",
        "\n",
        "print(\"Best SVM training error: %f\" % training_error)\n",
        "print(\"Best SVM test error: %f\" % test_error)\n",
        "\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "lr = linear_model.LogisticRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "\n",
        "training_error = 1. - lr.score(X_train, y_train)\n",
        "test_error = 1. - lr.score(X_test, y_test)\n",
        "\n",
        "print(\"Best logistic regression training error: %f\" % training_error)\n",
        "print(\"Best logistic regression test error: %f\" % test_error)\n",
        "\n",
        "\n",
        "lr_cv = linear_model.LogisticRegressionCV(cv=cv, random_state=0)\n",
        "\n",
        "training_error_cv = 1. - sklearn.model_selection.cross_val_score(lr_cv, X_train, y_train, cv=cv).mean()\n",
        "\n",
        "lr_cv.fit(X_train, y_train)\n",
        "\n",
        "test_error_cv = 1. - lr_cv.score(X_test, y_test)\n",
        "\n",
        "print(\"Best logistic regression training error: %f\" % training_error_cv)\n",
        "print(\"Best logistic regression test error: %f\" % test_error_cv)\n",
        "\n",
        "print(\"-----------------------------------------------------------------------\")\n",
        "#-------------------------------------------------------------------------------\n",
        "\n",
        "y_pred_SVM = best_SVM.predict(X_test)\n",
        "y_pred_lr = lr_cv.predict(X_test)\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  if y_test[i] != y_pred_lr[i]:\n",
        "    if y_test[i] == y_pred_SVM[i]:\n",
        "      plot_digit(X_test, y_test, i)\n",
        "      print(\"Logistic regression Label: %s\" % y_pred_lr[i])\n",
        "      print(\"SVM Label: %s\" % y_pred_SVM[i])\n",
        "      break\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nUKOWjV79OEe",
        "outputId": "bfa0f4d2-51f5-45ab-fe4d-c8f1cc77eda5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels and their frequencies in the training dataset: \n",
            "0: 119\n",
            "1: 114\n",
            "2: 98\n",
            "3: 99\n",
            "4: 106\n",
            "5: 82\n",
            "6: 97\n",
            "7: 103\n",
            "8: 91\n",
            "9: 91\n",
            "-----------------------------------------------------------------------\n",
            "RESULTS FOR LINEAR KERNEL\n",
            "\n",
            "Best parameters set found:\n",
            "{'C': 1}\n",
            "Score with best parameters:\n",
            "0.8639999999999999\n",
            "\n",
            "All scores on the grid:\n",
            "Mean Score: 0.8639999999999999\n",
            "Parameters: {'C': 1}\n",
            "\n",
            "Mean Score: 0.8639999999999999\n",
            "Parameters: {'C': 10}\n",
            "\n",
            "Mean Score: 0.8639999999999999\n",
            "Parameters: {'C': 100}\n",
            "\n",
            "\n",
            "RESULTS FOR POLY DEGREE=2 KERNEL\n",
            "\n",
            "Best parameters set found:\n",
            "{'C': 1, 'gamma': 0.1}\n",
            "Score with best parameters:\n",
            "0.883\n",
            "\n",
            "All scores on the grid:\n",
            "Mean Score: 0.867\n",
            "Parameters: {'C': 1, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 1, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 1, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.882\n",
            "Parameters: {'C': 10, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 10, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 10, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 100, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 100, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.883\n",
            "Parameters: {'C': 100, 'gamma': 1.0}\n",
            "\n",
            "\n",
            "RESULTS FOR RBF KERNEL\n",
            "\n",
            "Best parameters set found:\n",
            "{'C': 10, 'gamma': 0.01}\n",
            "Score with best parameters:\n",
            "0.8930000000000001\n",
            "\n",
            "All scores on the grid:\n",
            "Mean Score: 0.8860000000000001\n",
            "Parameters: {'C': 1, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.529\n",
            "Parameters: {'C': 1, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.128\n",
            "Parameters: {'C': 1, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.8930000000000001\n",
            "Parameters: {'C': 10, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.575\n",
            "Parameters: {'C': 10, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.134\n",
            "Parameters: {'C': 10, 'gamma': 1.0}\n",
            "\n",
            "Mean Score: 0.8930000000000001\n",
            "Parameters: {'C': 100, 'gamma': 0.01}\n",
            "\n",
            "Mean Score: 0.575\n",
            "Parameters: {'C': 100, 'gamma': 0.1}\n",
            "\n",
            "Mean Score: 0.134\n",
            "Parameters: {'C': 100, 'gamma': 1.0}\n",
            "\n",
            "-----------------------------------------------------------------------\n",
            "Best SVM training error: 0.000000\n",
            "Best SVM test error: 0.085304\n",
            "-----------------------------------------------------------------------\n",
            "Best logistic regression training error: 0.000000\n",
            "Best logistic regression test error: 0.135246\n",
            "Best logistic regression training error: 0.151000\n",
            "Best logistic regression test error: 0.137768\n",
            "-----------------------------------------------------------------------\n",
            "INPUT:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LABEL: 8\n",
            "Logistic regression Label: 5\n",
            "SVM Label: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gkWCjdVnXg9"
      },
      "source": [
        "## Section 7\n",
        "Compare and comment on the differences with the results above."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we see, by doubling the size of the train data, both methods, performed better on the test set. This is because by increasing the train data the models have access to a larger and more diverse set of examples. This can help improve their ability to generalize patterns and make accurate predictions on unseen data. Also, increasing the training data can help mitigate overfitting, which occurs when a model becomes too specific to the training set and fails to generalize well. With more data, the models are exposed to a wider range of instances and are less likely to memorize specific training examples. This can lead to better generalization performance and a decrease in overfitting.\n",
        "\n",
        "There is also a probability of decreasing in the output depending on the dataset added."
      ],
      "metadata": {
        "id": "gOC4tiqbCPe3"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}